---
title: "Media advocacy promotes in-person and online audiences' engagement with social justice cause through empathy"
shorttitle: "Media advocacy and audience engagement"
author:
  - name: Joshua L. Schlichting
    orcid: 0000-0001-8239-5197
    email: schlichj@mcmaster.ca
    roles:
      - conceptualization
      - methodology
      - investigation
      - software
      - visualization
      - data curation
      - formal analysis  
      - validation
      - writing
    affiliations:
      - id: id1
        name: "McMaster University"
        department: Department of Psychology, Neuroscience & Behaviour
        address: 1280 Main Street West
        city: Hamilton
        region: ON
        country: Canada
        postal-code: L8S 4K1
  - name: Lauren K. Fink
    orcid: 0000-0001-6699-750X
    corresponding: true
    roles:
      - conceptualization
      - methodology
      - investigation
      - funding acquisition
      - project administration
      - resources
      - supervision
      - editing
    affiliations: 
      - ref: id1
blank-lines-above-author-note: 2
author-note:
  # Disclosures condensed to one paragraph, but you can start a field with two line breaks to break them up: \n\nNew Paragraph
  disclosures:
    study-registration: "The design, hypotheses, and analysis plan for study 2 were preregistered; see TODO."
    data-sharing: "Data and code from this manuscript can be accessed at TODO."
    related-report: "This article is based on the thesis completed by Schlichting (2025)."
    conflict-of-interest: The authors have no conflicts of interest to disclose.
    financial-support: "JLS was supported by a scholarship of the German Academic Exchange Service (DAAD)."
    gratitude: "The authors would like to thank Allen Otte, John Lane, and Wojciech Lorenc for their artistic contribution, Innocence Canada for the provision of insights and materials, the LIVELab and BEAT Lab team for their crucial support in facilitating the live event, and Laurel Trainor and John Iversen for thoughtful comments on the project."
abstract: "TODO"
keywords: [music, film, media, social justice, prosocial, bonding, empathy, norm activation]
impact-statement: ~
floatsintext: true
numbered-lines: true
bibliography: innocentsref.bib
suppress-title-page: false
link-citations: true
# TODO set to true for peer review. Masks author info & references that appear in the masked-citations list
mask: false
masked-citations:
  - schneider2012cattell
  - schneider2015intelligence
# If true, adds today's date below author affiliations. If text, can be any value.
# This is not standard APA format, but it is convenient.
# Works with docx, html, and typst. 
draft-date: false
lang: en
language:
  citation-last-author-separator: "and"
  citation-masked-author: "Masked Citation"
  citation-masked-date: "n.d."
  citation-masked-title: "Masked Title"
  email: "Email"
  title-block-author-note: "Author Note"
  title-block-correspondence-note: "Correspondence concerning this article should be addressed to"
  title-block-role-introduction: "Author roles were classified using the Contributor Role Taxonomy (CRediT; [credit.niso.org](https://credit.niso.org)) as follows:"
  title-impact-statement: "Impact Statement"
format:
  apaquarto-docx: 
    toc: false
  apaquarto-pdf:
    # Can be jou (journal), man (manuscript), stu (student), or doc (document)
    documentmode: man
    keep-tex: true
---

```{r}
#| label: setup
#| include: false

# clear environment
rm(list=ls())

# load/install required packages
require(pacman)
p_load('tidyverse', 'ggplot2', 'ggpubr', 'ggridges', 'ggsignif', 'ggnewscale', 'here', 'lmerTest', 'car', 'psych', 'performance', 'corrplot', 'sjPlot', 'papaja', 'stringdist', 'wordcloud', 'MASS', 'pwr', 'effsize', 'png', 'grid', 'ltm', 'conflicted', 'flextable', 'ftExtra', 'knitr', 'tinytable')

# set preferences in case of command conflicts between loaded packages
conflicts_prefer(dplyr::select, .quiet = TRUE)
conflicts_prefer(dplyr::filter, .quiet = TRUE)
conflicts_prefer(flextable::separate_header, .quiet = TRUE)

# load custom functions
source(here("src/LMMfunctions.R"), local = knitr::knit_global()) 

# sessionInfo()

#### PLOTTING PARAMETERS ###

# set custom colour palette
ordermedium_cols <- c("#FFB000", "#661BFF", "#1D95FF", "#FFEB00") # "F-P: Film", "F-P: Performance", "P-F: Performance", "P-F: Film"  
# NeuroMusic palette: "#6472FF", "#FE6100", "#FFB000", "#8ECEFE"
medium_cols <- ordermedium_cols[c(1, 2)] # Film, Performance

# load icons
icon_close <- readPNG(here("images/Innocents_Icon_Closeness.png"))
icon_empath <- readPNG(here("images/Innocents_Icon_Empathy.png"))
icon_aware <- readPNG(here("images/Innocents_Icon_Awareness.png"))
icon_intent <- readPNG(here("images/Innocents_Icon_Intention.png"))
icon_behav <- readPNG(here("images/Innocents_Icon_Behaviour.png"))
```

```{r}
#| label: prepstudy1
#| include: false

# load study 1 data
here::i_am("Innocents_Prosociality_Manuscript.qmd") # find project root
study1_df_deident <- read_csv(here("data/innocents_df_deident.csv")) # TODO load deident df, then calculate indices in here

#### Exclude responses that lack variance ###
# TODO discuss with Lauren whether to check variance per instrument or per survey page
# define mapping of variables to scales to instruments
study1_instruments <- list(
  base_ios = list(
    base_ios = c("base_ios_allen", "base_ios_john", "base_ios_anna", "base_ios_inperson", "base_ios_remote")),
  base_anna_empathy = list(
    base_anna_empathic_concern = c("base_ec1", "base_ec2", "base_ec3", "base_ec4", "base_ec5", "base_ec6"),
    base_anna_personal_distress = c("base_pd1", "base_pd2", "base_pd3", "base_pd4", "base_pd5", "base_pd6", "base_pd7", "base_pd8")),
  base_namtpb = list(
    base_problem_awareness = c("base_nam1", "base_nam2", "base_nam3", "base_nam4"),
    base_ascribed_responsibility = c("base_nam5", "base_nam6", "base_nam7", "base_nam8"),
    base_personal_norm = c("base_nam9", "base_nam10", "base_nam11", "base_nam12"),
    base_attitude = c("base_tpb1", "base_tpb2", "base_tpb3", "base_tpb4"),
    base_subjective_norm = c("base_tpb5", "base_tpb6", "base_tpb7", "base_tpb8"),
    base_behavioural_control = c("base_tpb9", "base_tpb10", "base_tpb11", "base_tpb12"),
    base_behavioural_intention = c("base_tpb13", "base_tpb14", "base_tpb15")),
  base_affect = list(
    base_affect = grep("base_emotion", colnames(study1_df_deident), value = TRUE)),
  perfo_affect = list(
    perfo_affect = grep("perfo_emotion", colnames(study1_df_deident), value = TRUE)),
  perfo_engagement = list(
    perfo_engagement = c("perfo_enjoy", "perfo_interest", "perfo_moved", "perfo_insight", "perfo_concentration", "perfo_chills", "perfo_tears", "perfo_reengage")),
  perfo_ios = list(
    perfo_ios = c("perfo_ios_allen", "perfo_ios_john", "perfo_ios_anna", "perfo_ios_inperson", "perfo_ios_remote")),
  perfo_anna_empathy = list(
    perfo_anna_empathic_concern = c("perfo_ec1", "perfo_ec2", "perfo_ec3", "perfo_ec4", "perfo_ec5", "perfo_ec6"),
    perfo_anna_personal_distress = c("perfo_pd1", "perfo_pd2", "perfo_pd3", "perfo_pd4", "perfo_pd5", "perfo_pd6", "perfo_pd7", "perfo_pd8")),
  perfo_namtpb = list(
    perfo_problem_awareness = c("perfo_nam1", "perfo_nam2", "perfo_nam3", "perfo_nam4"),
    perfo_behavioural_intention = c("perfo_tpb13", "perfo_tpb14", "perfo_tpb15")),
  docu_affect = list(
    docu_affect = grep("docu_emotion", colnames(study1_df_deident), value = TRUE)),
  docu_engagement = list(
    docu_engagement = c("docu_enjoy", "docu_interest", "docu_moved", "docu_insight", "docu_concentration", "docu_chills", "docu_tears", "docu_reengage")),
  docu_ios = list(
    docu_ios = c("docu_ios_allen", "docu_ios_john", "docu_ios_anna", "docu_ios_inperson", "docu_ios_remote")),
  docu_anna_empathy = list(
    docu_anna_empathic_concern = c("docu_ec1", "docu_ec2", "docu_ec3", "docu_ec4", "docu_ec5", "docu_ec6"),
    docu_anna_personal_distress = c("docu_pd1", "docu_pd2", "docu_pd3", "docu_pd4", "docu_pd5", "docu_pd6", "docu_pd7", "docu_pd8")),
  docu_namtpb = list(
    docu_problem_awareness = c("docu_nam1", "docu_nam2", "docu_nam3", "docu_nam4"),
    docu_behavioural_intention = c("docu_tpb13", "docu_tpb14", "docu_tpb15")),
  post_namtpb = list(
    post_ascribed_responsibility = c("post_nam5", "post_nam6", "post_nam7", "post_nam8"),
    post_personal_norm = c("post_nam9", "post_nam10", "post_nam11", "post_nam12"),
    post_attitude = c("post_tpb1", "post_tpb2", "post_tpb3", "post_tpb4"),
    post_subjective_norm = c("post_tpb5", "post_tpb6", "post_tpb7", "post_tpb8"),
    post_behavioural_control = c("post_tpb9", "post_tpb10", "post_tpb11", "post_tpb12")),
  demo_openness = list(
    demo_openness = grep("open", colnames(study1_df_deident), value = TRUE)),
  demo_trait_empathy = list(
    trait_empathic_concern = c("iri2", "iri4", "iri9", "iri14", "iri18", "iri20", "iri22"),
    trait_personal_distress = c("iri6", "iri10", "iri13", "iri17", "iri19", "iri24", "iri27")
  )
)

#### CHECK FOR SUFFICIENT VARIANCE ACROSS ITEMS OF ONE INSTRUMENT ###
variance_for_manyitems <- 2
variance_for_fewitems <- 1
threshold_fewormanyitems <- 10

study1_df_variance <- study1_df_deident %>% # make copy of dataframe
  rename_with(
    .fn = ~ str_replace(., "^final_", "post_"), # rename final_ to post_ for consistency
    .cols = starts_with("final_")
  )

study1_total_instrument_observations <- 0 # counter for total instruments checked across participants
study1_novariance_observations <- 0 # counter for instruments with lack of variance

# iterate over instruments
for (instrument in names(study1_instruments)) {
  # get all item columns of the instrument
  items <- c()
  for (scale in names(study1_instruments[[instrument]])) {
    items <- c(items, study1_instruments[[instrument]][[scale]])
  }
  
  # count unique values and store in new column
  unique_column <- paste0(instrument, "_unique") # name of the new column that stores the number of unique values
  study1_df_variance <- study1_df_variance %>%
    rowwise() %>%
    mutate(!!unique_column := n_distinct(c_across(all_of(items)), na.rm = TRUE)) %>%
    ungroup()
  
  # count number of observations that lack variances
  cutoff <- ifelse(length(items) > threshold_fewormanyitems, variance_for_manyitems, variance_for_fewitems) # define what constitutes a lack of variance depending on the number of items in the instrument
  
  total <- sum(!is.na(study1_df_variance[[unique_column]])) # count total observations per instrument
  novariance <- sum(study1_df_variance[[unique_column]] <= cutoff, na.rm = TRUE) # count cases where unique values are below cutoff
  
  study1_total_instrument_observations = study1_total_instrument_observations + total # update counters
  study1_novariance_observations = study1_novariance_observations + novariance
}

rm(instrument, items, scale, unique_column, cutoff, total, novariance, study1_df_deident)

#### RECODE REVERSE-CODED ITEMS ###

study1_df_recoded <- study1_df_variance %>%
  rowwise() %>%
  mutate(across(.cols = c(age, caffeine, liking, income, education, politics, mailing),
                .fns = ~ case_match(.x, -1 ~ NA, -9 ~ NA, .default = .x)), # recode "prefer not to answer" as NA
         across(.cols = c(base_nam3, base_tpb11, perfo_nam3, docu_nam3, post_tpb11),
                .fns = ~ 8 - .x),
         across(.cols = c(open1, open6, open11, iri4, iri13, iri14, iri18, iri19),
                .fns = ~ 6 - .x),
         flyer = replace(flyer, is.na(flyer), 0)) %>% # for online participants, those who did not click the resource had NA here; set to 0
  ungroup() 

rm(study1_df_variance)

#### cALCULATE CONSTRUCT SCORES IF AT LEAST 80% OF ITEMS HAVE BEEN ANSWERED AND IF THERE IS SUFFICIENT VARIANCE ###

study1_df <- study1_df_recoded %>%
  rowwise() %>%
  mutate(
    # calculate affect scales
    base_pleasure = base_emotion3 - base_emotion6,
    base_awake = base_emotion5 - base_emotion1,
    base_tense = base_emotion2 - base_emotion4,
    perfo_pleasure = perfo_emotion3 - perfo_emotion6,
    perfo_awake = perfo_emotion5 - perfo_emotion1,
    perfo_tense = perfo_emotion2 - perfo_emotion4,
    docu_pleasure = docu_emotion3 - docu_emotion6,
    docu_awake = docu_emotion5 - docu_emotion1,
    docu_tense = docu_emotion2 - docu_emotion4
  ) %>%
  ungroup()

# iterate over instruments
for (instrument in names(study1_instruments)) {
  if (instrument %in% c("base_ios", "base_affect", "perfo_ios", "perfo_affect", "perfo_engagement", "docu_ios", "docu_affect", "docu_engagement")) next # skip instruments that should not be averaged
  
  unique_column <- paste0(instrument, "_unique") # name of the column that stores the number of unique values
  
  # get all item columns of the instrument
  instrument_items <- c()
  for (scale in names(study1_instruments[[instrument]])) {
    instrument_items <- c(instrument_items, study1_instruments[[instrument]][[scale]])
  }
  
  cutoff <- ifelse(length(instrument_items) > threshold_fewormanyitems, variance_for_manyitems, variance_for_fewitems) # define what constitutes a lack of variance depending on the number of items in the instrument
  
  # iterate over scales
  for (scale in names(study1_instruments[[instrument]])) {
    scale_items <- study1_instruments[[instrument]][[scale]]
    
    # Average rowwise if conditions are met using apply()
    study1_df[[scale]] <- apply(study1_df[scale_items], 1, calculate_scale_score, unique_column = unique_column, cutoff = cutoff)
  }
}

rm(study1_instruments, instrument, unique_column, instrument_items, cutoff, scale, scale_items, study1_df_recoded, variance_for_manyitems, variance_for_fewitems, threshold_fewormanyitems)

# rename multiple choice options to have meaningful names
study1_df <- study1_df %>%
  rename(base_intent_mailing = base_tpb13,
         base_intent_flyer = base_tpb14,
         base_intent_donation = base_tpb15,
         perfo_intent_mailing = perfo_tpb13,
         perfo_intent_flyer = perfo_tpb14,
         perfo_intent_donation = perfo_tpb15,
         docu_intent_mailing = docu_tpb13,
         docu_intent_flyer = docu_tpb14,
         docu_intent_donation = docu_tpb15,
         motivation_curious = motivation1,
         motivation_interested = motivation2,
         motivation_socialjustice = motivation3,
         motivation_helpresearch = motivation4,
         motivation_enjoy = motivation5,
         relationship_artist = relationship1,
         relationship_researcher = relationship2,
         relationship_none = `relationship-1`,
         identity_woman = identity1,
         identity_genderdiverse = identity2,
         identity_lgbq = identity3,
         identity_indigenous = identity4,
         identity_poc = identity5,
         identity_none = `identity-1`,
         identity_NA = `identity-9`,
         experience_disability = experience1,
         experience_charges = experience2,
         experience_unsheltered = experience3,
         experience_none = `experience-1`,
         experience_NA = `experience-9`)

# recode motivation variables
study1_df <- study1_df %>%
  mutate(across(
    .cols = starts_with("motivation_"),
    .fns = ~ ifelse(!is.na(.), 1, 0)
  ))

# set dummy variable indicating whether participant completed both halves of the event (copied from Schlichting_MSc_Thesis.Rmd)
study1_df$completed <- ifelse(study1_df$NA_count.event <= 59, 1, 0) # cutoff determined upon inspection of the data, see 003_event_preprocessing.Rmd

# if only interested in participants who stayed until the end, filter participants who left at intermission:
# study1_df <- study1_df %>%
#   filter(NA_count.event <= 59) 

# factorize order and attendance (copied from Schlichting_MSc_Thesis.Rmd)
study1_df <- study1_df %>%
  mutate(order = factor(order, levels=c("film-perfo", "perfo-film"), labels=c("Film first", "Perf first")),
         attendance = factor(attendance, levels=c("in-person", "livestream"), labels=c("In-person", "Livestream")),
         base_behavioural_intention_z = my_z_score(base_behavioural_intention),
         cell = factor(interaction(order, attendance), levels = c("Film first.In-person", "Film first.Livestream", "Perf first.In-person", "Perf first.Livestream"), labels = c("F-P: In-person", "F-P: Livestream", "P-F: In-person", "P-F: Livestream"))) %>%
  rowwise() %>%
  # compute behaviour indices
  mutate(sum_behaviour = ifelse(completed == 0, NA, sum(mailing, flyer, post_donation)),
         sum_behaviour_fact = factor(sum_behaviour, levels = c("0", "1", "2", "3"), ordered = TRUE),
         sum_behaviour_inclNA = ifelse(completed == 0, NA, sum(mailing, flyer, post_donation, na.rm = TRUE)),
         behaviour_dich = ifelse(completed == 0, NA, 
                                 ifelse(sum_behaviour_inclNA %in% c(1:3), 1, 0)))


#### DF over 2 timepoints (intermission, end) for baseline-corrected analyses (copied from Schlichting_MSc_Thesis.Rmd) ###

docu_vars <- grep("^docu_", colnames(study1_df), value=TRUE)
perfo_vars <- grep("^perfo_", colnames(study1_df), value=TRUE)
docu_vars <- setdiff(docu_vars, "docu_understand_anna")
# perfo_vars <- setdiff(perfo_vars, grep("describe", perfo_vars, value=TRUE))

study1_2long <- study1_df %>%
  pivot_longer(all_of(c(docu_vars, perfo_vars)), names_to = c("medium", ".value"), names_pattern = "^(.*?)_(.*)$") %>%
  mutate(medium = factor(medium, levels=c("docu", "perfo"), labels=c("Film", "Performance")), # factorize medium
         timepoint = factor(interaction(day, medium), levels = c("0.Film", "1.Film", "0.Performance", "1.Performance"), labels = c("Intermission", "End", "End", "Intermission")), # determine timepoint
         ordermedium = factor(interaction(day, medium), levels = c("0.Film", "0.Performance", "1.Performance", "1.Film"), labels = c("F-P: Film", "F-P: Performance", "P-F: Performance", "P-F: Film")), # concatenate order and medium
         cell = factor(paste(attendance, order, medium, sep="."))) %>% # concatenate attendance, order, & medium
  mutate(across(.cols = all_of(c("base_ios_anna", "base_anna_empathic_concern", "base_problem_awareness", "base_behavioural_intention", "base_anna_personal_distress", "ios_anna", "anna_empathic_concern", "problem_awareness", "behavioural_intention", "anna_personal_distress")), .fns = my_z_score, .names = "{.col}_z")) %>% # z-score variables
  rowwise() %>%
  mutate(sum_behaviour = sum(mailing, flyer, post_donation),
         sum_behaviour_fact = factor(sum_behaviour, levels = c("0", "1", "2", "3"), ordered = TRUE),
         sum_behaviour_inclNA = sum(mailing, flyer, post_donation, na.rm = TRUE)) %>%
  ungroup()

# set contrasts
contrasts(study1_2long$order) <- cbind(FPvsPF = c(1, -1))
# attr(,"contrasts")
#           FPvsPF
# Film first      1
# Perf first     -1
# Levels: Film first Perf first

contrasts(study1_2long$medium) <- cbind(PerfvsFilm = c(-1, 1))
# attr(,"contrasts")
#             PerfvsFilm
# Film                -1
# Performance          1
# Levels: Film Performance

contrasts(study1_2long$timepoint) <- cbind(EndvsInter = c(-1, 1))
# attr(,"contrasts")
#              EndvsInter
# Intermission         -1
# End                   1
# Levels: Intermission End

contrasts(study1_2long$attendance) <- cbind(InpersonvsStream = c(1, -1))
# attr(,"contrasts")
#            InpersonvsStream
# In-person                 1
# Livestream               -1
# Levels: In-person Livestream

# dichotomize control variable
study1_2long <- study1_2long %>%
  mutate(
  motivation_socialjustice_dich = factor(motivation_socialjustice, levels = c(0, 1), labels = c("No", "Yes")))
contrasts(study1_2long$motivation_socialjustice_dich) <- cbind(YesvsNo = c(-1, 1))

# z-score control variables
study1_2long$trait_empathic_concern_z <- my_z_score(study1_2long$trait_empathic_concern)
study1_2long$politics_z <- my_z_score(study1_2long$politics)
study1_2long$trait_openness_z <- my_z_score(study1_2long$demo_openness)



#### DF over three timepoints (base, intermission, end) for plotting (copied from Schlichting_MSc_Thesis.Rmd) ###

# get names of variables that were tested across three timepoints
base_vars <- grep("^base_", colnames(study1_df), value=TRUE)
post_vars <- grep("^post_", colnames(study1_df), value=TRUE)

# gather to long format across base, docu, and perfo timepoints
study1_3long <- study1_df %>%
  pivot_longer(all_of(c(base_vars, docu_vars, perfo_vars, post_vars)), names_to = c("medium", ".value"), names_pattern = "^(.*?)_(.*)$") %>%
  # merge post measures with the medium that came last
  mutate(
    medium = case_when(
      medium == "post" & order == "Film first" ~ "perfo",
      medium == "post" & order == "Perf first" ~ "docu",
      TRUE ~ medium
    )
  ) %>%
  # pivot_long over post_vars introduced duplicate rows, so summarise those duplicates into one row by taking the first non-NA value for each variable
  group_by(p_id, medium) %>%
  summarise(across(everything(), ~ first(na.omit(.))), .groups = "drop") %>% 
  mutate(medium = factor(medium, levels=c("base", "docu", "perfo"), labels=c("Baseline", "Film", "Performance")),
         timepoint = factor(interaction(day, medium), levels = c("0.Baseline", "1.Baseline", "0.Film", "1.Film", "0.Performance", "1.Performance"), labels = c("Baseline", "Baseline", "Intermission", "End", "End", "Intermission"))) %>%
  arrange(p_id, match(timepoint, c("Baseline", "Intermission", "End"))) %>%
  # rename personal distress/empathic concern variables to specify target
  rename_with(.fn = ~ paste0("anna_", .), .cols = c(starts_with("pd"), starts_with("ec")))

rm(base_vars, docu_vars, perfo_vars, post_vars)
```

```{r}
#| label: prepstudy2
#| include: false

# load study 2 data
study2_df_deident <- read_csv(here("data/study2_df_deident.csv"))

# define mapping of variables to scales to instruments
study2_instruments <- list(
  base_target_empathy = list(
    base_target_empathic_concern = c("base_target_ec1", "base_target_ec2", "base_target_ec3", "base_target_ec4", "base_target_ec5", "base_target_ec6"),
    base_target_personal_distress = c("base_target_pd1", "base_target_pd2", "base_target_pd3", "base_target_pd4", "base_target_pd5", "base_target_pd6", "base_target_pd7", "base_target_pd8")),
  base_ios = list(
    base_ios = c("base_ios_allen", "base_ios_john", "base_ios_anna", "base_ios_inperson", "base_ios_remote")),
  base_anna_empathy = list(
    base_anna_empathic_concern = c("base_anna_ec1", "base_anna_ec2", "base_anna_ec3", "base_anna_ec4", "base_anna_ec5", "base_anna_ec6"),
    base_anna_personal_distress = c("base_anna_pd1", "base_anna_pd2", "base_anna_pd3", "base_anna_pd4", "base_anna_pd5", "base_anna_pd6", "base_anna_pd7", "base_anna_pd8")),
  base_namtpb = list(
    base_problem_awareness = c("base_nam1", "base_nam2", "base_nam3", "base_nam4"),
    base_ascribed_responsibility = c("base_nam5", "base_nam6", "base_nam7", "base_nam8"),
    base_personal_norm = c("base_nam9", "base_nam10", "base_nam11", "base_nam12"),
    base_attitude = c("base_tpb1", "base_tpb2", "base_tpb3", "base_tpb4"),
    base_subjective_norm = c("base_tpb5", "base_tpb6", "base_tpb7", "base_tpb8"),
    base_behavioural_control = c("base_tpb9", "base_tpb10", "base_tpb11", "base_tpb12"),
    base_behavioural_intention = c("base_tpb13", "base_tpb14", "base_tpb15")),
  base_affect = list(
    base_affect = grep("base_emotion", colnames(study2_df_deident), value = TRUE)),
  post_affect = list(
    post_affect = grep("post_emotion", colnames(study2_df_deident), value = TRUE)),
  post_engagement = list(
    post_engagement = c("enjoy", "interest", "moved", "insight", "concentration", "chills", "tears", "reengage")),
  post_target_empathy = list(
    post_target_empathic_concern = c("post_target_ec1", "post_target_ec2", "post_target_ec3", "post_target_ec4", "post_target_ec5", "post_target_ec6"),
    post_target_personal_distress = c("post_target_pd1", "post_target_pd2", "post_target_pd3", "post_target_pd4", "post_target_pd5", "post_target_pd6", "post_target_pd7", "post_target_pd8")),
  post_ios = list(
    post_ios = c("post_ios_allen", "post_ios_john", "post_ios_anna", "post_ios_inperson", "post_ios_remote")),
  post_anna_empathy = list(
    post_anna_empathic_concern = c("post_anna_ec1", "post_anna_ec2", "post_anna_ec3", "post_anna_ec4", "post_anna_ec5", "post_anna_ec6"),
    post_anna_personal_distress = c("post_anna_pd1", "post_anna_pd2", "post_anna_pd3", "post_anna_pd4", "post_anna_pd5", "post_anna_pd6", "post_anna_pd7", "post_anna_pd8")),
  post_namtpb = list(
    post_problem_awareness = c("post_nam1", "post_nam2", "post_nam3", "post_nam4"),
    post_ascribed_responsibility = c("post_nam5", "post_nam6", "post_nam7", "post_nam8"),
    post_personal_norm = c("post_nam9", "post_nam10", "post_nam11", "post_nam12"),
    post_attitude = c("post_tpb1", "post_tpb2", "post_tpb3", "post_tpb4"),
    post_subjective_norm = c("post_tpb5", "post_tpb6", "post_tpb7", "post_tpb8"),
    post_behavioural_control = c("post_tpb9", "post_tpb10", "post_tpb11", "post_tpb12"),
    post_behavioural_intention = c("post_tpb13", "post_tpb14", "post_tpb15")),
  demo_openness = list(
    demo_openness = grep("open", colnames(study2_df_deident), value = TRUE))
)


#### CHECK FOR SUFFICIENT VARIANCE ACROSS ITEMS OF ONE INSTRUMENT ###
variance_for_manyitems <- 2
variance_for_fewitems <- 1
threshold_fewormanyitems <- 10

study2_df_variance <- study2_df_deident %>% # make copy of dataframe
  rename_with(
    .fn = ~ str_replace(., "^post_", ""), # rename engagement variables for consistency with study1
    .cols = c("post_enjoy", "post_interest", "post_moved", "post_insight", "post_concentration", "post_chills", "post_tears", "post_reengage")
  )

study2_total_instrument_observations <- 0 # counter for total instruments checked across participants
study2_novariance_observations <- 0 # counter for instruments with lack of variance

# iterate over instruments
for (instrument in names(study2_instruments)) {
  # get all item columns of the instrument
  items <- c()
  for (scale in names(study2_instruments[[instrument]])) {
    items <- c(items, study2_instruments[[instrument]][[scale]])
  }
  
  # count unique values and store in new column
  unique_column <- paste0(instrument, "_unique") # name of the new column that stores the number of unique values
  study2_df_variance <- study2_df_variance %>%
    rowwise() %>%
    mutate(!!unique_column := n_distinct(c_across(all_of(items)), na.rm = TRUE)) %>%
    ungroup()
  
  # count number of observations that lack variances
  cutoff <- ifelse(length(items) > threshold_fewormanyitems, variance_for_manyitems, variance_for_fewitems) # define what constitutes a lack of variance depending on the number of items in the instrument
  
  total <- sum(!is.na(study2_df_variance[[unique_column]])) # count total observations per instrument
  novariance <- sum(study2_df_variance[[unique_column]] <= cutoff, na.rm = TRUE) # count cases where unique values are below cutoff
  
  study2_total_instrument_observations = study2_total_instrument_observations + total # update counters
  study2_novariance_observations = study2_novariance_observations + novariance
}

rm(instrument, items, scale, unique_column, cutoff, total, novariance, study2_df_deident)



#### RECODE REVERSE-CODED ITEMS ###

study2_df_recoded <- study2_df_variance %>%
  rowwise() %>%
  mutate(across(.cols = c(age, caffeine, liking, income, education, politics, mailing),
                .fns = ~ case_match(.x, -9 ~ NA, .default = .x)),
         resource_click = case_match(resource_noclick, 0 ~ FALSE, .default = resource_click),
         donation_click = case_match(donation_noclick, 0 ~ FALSE, .default = donation_click),
         across(.cols = c(base_nam3, base_tpb11, post_nam3, post_tpb11),
                .fns = ~ 8 - .x),
         across(.cols = c(open1, open6, open11),
                .fns = ~ 6 - .x)) %>%
  ungroup() %>%
  select(-c(resource_noclick, donation_noclick))

rm(study2_df_variance)



#### cALCULATE CONSTRUCT SCORES IF AT LEAST 80% OF ITEMS HAVE BEEN ANSWERED AND IF THERE IS SUFFICIENT VARIANCE ###

study2_df <- study2_df_recoded %>%
  rowwise() %>%
  mutate(
    # calculate affect scales
    base_pleasure = base_emotion3 - base_emotion6,
    base_awake = base_emotion5 - base_emotion1,
    base_tense = base_emotion2 - base_emotion4,
    post_pleasure = post_emotion3 - post_emotion6,
    post_awake = post_emotion5 - post_emotion1,
    post_tense = post_emotion2 - post_emotion4
  ) %>%
  ungroup()

# iterate over instruments
for (instrument in names(study2_instruments)) {
  if (instrument %in% c("base_ios", "base_affect", "post_affect", "post_engagement", "post_ios")) next # skip instruments that should not be averaged
  
  unique_column <- paste0(instrument, "_unique") # name of the column that stores the number of unique values
  
  # get all item columns of the instrument
  instrument_items <- c()
  for (scale in names(study2_instruments[[instrument]])) {
    instrument_items <- c(instrument_items, study2_instruments[[instrument]][[scale]])
  }
  
  cutoff <- ifelse(length(instrument_items) > threshold_fewormanyitems, variance_for_manyitems, variance_for_fewitems) # define what constitutes a lack of variance depending on the number of items in the instrument
  
  # iterate over scales
  for (scale in names(study2_instruments[[instrument]])) {
    scale_items <- study2_instruments[[instrument]][[scale]]
    
    # Average rowwise if conditions are met using apply()
    study2_df[[scale]] <- apply(study2_df[scale_items], 1, calculate_scale_score, unique_column = unique_column, cutoff = cutoff)
  }
}

rm(instrument, study2_instruments, unique_column, instrument_items, cutoff, scale, scale_items, study2_df_recoded, variance_for_manyitems, variance_for_fewitems, threshold_fewormanyitems)

# rename items to have meaningful names
study2_df <- study2_df %>%
  rename(base_intent_mailing = base_tpb13,
         base_intent_flyer = base_tpb14,
         base_intent_donation = base_tpb15,
         post_intent_mailing = post_tpb13,
         post_intent_flyer = post_tpb14,
         post_intent_donation = post_tpb15,
         identity_woman = identity4,
         # identity_genderdiverse = identity5, # TODO uncomment if full sample includes a genderdiverse participant
         identity_lgbq = identity3,
         identity_indigenous = identity1,
         identity_poc = identity2,
         identity_religious = identity6,
         identity_none = `identity-1`,
         # identity_NA = `identity-9`,
         experience_disability = experience1,
         experience_charges = experience2,
         experience_unsheltered = experience3,
         experience_none = `experience-1`,
         experience_NA = `experience-9`,
         flyer = resource_click) %>%
  # add metadata to match study 1
  mutate(order = case_match(group,
                            "group_film" ~ "Film first",
                            "group_perf" ~ "Perf first",
                            .default = group),
         attendance = "Livestream",
         p_nr = as.character(c(1:nrow(study2_df))),
         p_id = paste0("sub-on2", p_nr)
  )



#### DF over two timepoints (base, end) for plotting & analysis ###

# get names of variables that were tested across two timepoints
base_vars <- grep("^base_", colnames(study2_df), value=TRUE)
post_vars <- grep("^post_", colnames(study2_df), value=TRUE)

# remove non-overlapping variables
# post_vars <- setdiff(post_vars, grep("^post_describe", post_vars, value = TRUE))
# post_vars <- setdiff(post_vars, grep("^post_immersion", post_vars, value = TRUE))
# post_vars <- setdiff(post_vars, c("post_concentration", "post_moved", "post_tears", "post_enjoy", "post_interest", "post_chills", "post_reengage", "post_insight", "post_duration", "post_engagement_unique"))

# gather to long format across base, docu, and perfo timepoints
study2_long <- study2_df %>%
  pivot_longer(all_of(c(base_vars, post_vars)), names_to = c("timepoint", ".value"), names_pattern = "^(.*?)_(.*)$") %>%
  mutate(timepoint = factor(timepoint, levels = c("base", "post"), labels = c("Baseline", "End")),
         medium = case_when(
           timepoint == "Baseline" ~ "Baseline",
           timepoint == "End" & order == "Film first" ~ "Film",
           timepoint == "End" & order == "Perf first" ~ "Performance",
           TRUE ~ NA
         ))

rm(base_vars, post_vars)
```

```{r}
#| label: combinestudies
#| include: false

# Combine study 1 & 2 for plotting
combined_long <- study1_3long %>%
  bind_rows(study2_long, .id = "study") %>%
  mutate(facet = paste(study, attendance, sep = ":"))
```

Despite our shared struggle for a better world, societies remain unjust. For example, criminal justice systems were implemented to ensure a just society, but across governments, systemic issues lead to the wrongful imprisonment of innocent individuals. How do we mobilize support to fight social injustice such as wrongful imprisonment? Arts and media are a way of reaching and engaging broad audiences. Theatre, soap operas, and film, using the power of storytelling, can shape attitudes and behaviours with regards to social injustice. Music is also commonly used to advocate for social justice issues, for instance in the forms of charity concerts and protest songs. While previous research has uncovered how music shapes our evaluation of the people making the music or listening to it, few studies have investigated how music influences our views of people and issues that are the subject of music. Given that music typically has less narration than the previously studied media, it remains unclear how socially responsible music promotes audiences' engagement with social justice issues. In addition, theories of prosocial behaviour and social engagement put forward various predictors that could explain how arts and media can advocate for social justice issues. This plurality makes it difficult for researchers to integrate previous works, and for artists to understand which factors are decisive to effectively engage their audience.

Here, we evaluate how a music performance engages audiences with the issue of wrongful imprisonment, compared to a more narrative documentary film. We assess changes in three affective and cognitive variables, empathic concern, relationship closeness, and problem awareness, and compare their influence on audiences' supportive behaviour. This study provides empirical support for the mobilizing potential of music as a medium with less narration, and highlights which facet of audiences' attitudes artists should appeal to in order to gain support for their cause.

## Mobilizing support for social justice causes

<!-- Psychological models: what does advocacy try to achieve? How? Introduce potential mediators -->

The aim of social justice advocacy is to foster engagement with a social justice issue and mobilize supportive behaviour for that cause. Various psychological theories attempt to explain behaviour and could be applicable in the context of social justice advocacy. This plurality hinders theory integration across studies of socially responsible behaviour. It is therefore necessary to empirically compare the relevance of different theories and constructs for predicting the behaviour of interest [TODO CITE THAT DUTCH REVIEW]. In this study, we compare normative, empathic, and relational predictors. The following paragraphs will review the respective theoretical backgrounds, explaining support for social justice causes within the framework of the norm activation model [NAM; @schwartz1977], the empathy-altruism hypothesis [@batson1987], and the theory of bounded generalized reciprocity [@yamagishi1999].

Justice is a moral concept, and fighting injustices or supporting social justice causes can be conceived as morally-driven behaviour. The NAM lays out the process of how personal norms create a moral obligation to act. According to the model, an actor first has to become aware of a problematic situation like wrongful imprisonment, resulting in the knowledge that the current conditions of the situation will cause negative consequences for a person in need, like innocent prisoners. Subsequently, the actor evaluates their responsibility for the problem, coming to the conclusion that they can change the conditions to avert the negative consequences. As a third component, the problem must be relevant to the personal norms of the actor, like a just legal system or fighting injustices, so that the norms are activated and guide the behaviour in the situation. In combination, problem awareness, ascription of responsibility, and personal norms create a moral obligation for the actor to help solve the problem, thus acting in accordance with their norms [@schwartz1977; @degroot2009]. Importantly, the NAM postulates a causal chain of the three components, which explains why we do not always behave normatively: If we are not aware of a problem or we do not believe that we can change it, our norms do not activate in that situation and therefore do not guide our behaviour [although the empirical evidence regarding the causal chain is mixed; @klöckner2013].

Many studies [e.g., @savari2023; @degroot2009; @steg2010] integrate the NAM with the theory of planned behaviour [TPB; @ajzen1991; @ajzen2011]. While there is some conceptual overlap between the normative and belief components of the NAM and the TPB, the TPB contributes the behavioural intention as the most proximal predictor of behaviour. The idea is that rational (or planned) behaviour is necessarily preceded by a decision to engage in that behaviour. Therefore, all other determinants of behaviour influence this decision, which mediates the actual behaviour [@ajzen1991; @ajzen2011]. Separating intention and behaviour reduces noise in the analysis, because the translation of intention into behaviour can be hindered by external factors beyond the scope of studying what motivates actors to engage in a behaviour [e.g., lack of resources or unexpected situations; @sheeran2002]. In conclusion, social justice advocacy can mobilize supportive behaviour by raising awareness for a problem, appealing to the responsibility of its audience, or strengthening norms regarding social justice, which contribute to the intention to support the social justice cause. However, problem awareness might have to precede the other components, especially when the social justice issue is lesser known.

Alternatively to the normative framing, supporting social justice causes can be understood as altruistically motivated behaviour. According to the empathy-altruism hypothesis, empathically adopting the perspective of a person in need creates an altruistic motivation to reduce their suffering. For example, by empathizing with the experience of an innocent prisoner, an actor becomes concerned about their well-being, and thus feels motivated to help to improve the well-being of the innocent prisoner [@batson1987; @batson2011]. There has been a long debate on whether helping behaviour is motivated by altruistic concern in the interest of the other person, or by the actor's self-interest to reduce their own distress arising from witnessing the other person's suffering [@batson2011; @cialdini1997]. Both empathic concern and personal distress, however, arise from empathic perspective-taking. *TODO add that empathizing is effortful, therefore motivate audiences to empathize (rather than improve their ability to empathize; Weisz & Zaki, 2017).* Hence, social justice advocacy can mobilize supportive behaviour by conveying the experiences and point of view of those affected by the social justice issue, thereby facilitating empathic responses from the audience.

Finally, supporting social justice causes might be motivated by group cohesion. If we perceive victims of social injustice as part of our ingroup, we are more likely to fight social injustice to help those group members.

<!-- Finally, supporting social justice causes might be motivated by expectations of reciprocity. Through the lens of interpersonal relations, we are more likely to help those closer to us because xyz [@yamagishi1999]. Therefore, social justice advocacy can mobilize supportive behaviour by increasing the perceived relationship closeness between audiences and those affected by the social justice issue, which the audience to help in return for reciprocity xyz. -->

## Advocacy through art

Social injustices often become the subject of art. Beyond a mere inspiration or description of society, art is used to criticize social injustices and advocate for social justice. Empirical evaluations of such advocacy through art have proven effects of media like documentary films, theatre, and songs on the aforementioned normative, empathic, and relational dimensions, and on behaviour in support of social justice causes. For example, @reddan2024 compared audience responses to a documentary about wrongful imprisonment and two documentaries about injustices in sports, and found that the former enhanced audiences' empathic responses towards prisoners, attitudes towards prison reform, and intentions to support a petition to restore voting rights for people with felony convictions. Documentaries about personal life stories also increase social bonding with other audience members \[@dunbar2016\]. These studies are comparable to the somewhat larger body of literature attesting that documentaries about climate change increase audiences' concern and pro-environmental intentions \[@howell2011; @nolan2010; @sakellari2015\]. Turning to live media, audiences of theatre performances about disadvantaged groups have been shown to be more empathetic with the represented groups and more willing to donate to charity after the performance, compared to before. Effects on theatre audiences' attitudes remained ambiguous \[@rathje2021\]. Moreover, songs with prosocial lyrics like "Love Generation" by Bob Sinclair have been shown to prompt prosocial thoughts and empathic responses in listeners, with empathy mediating the effect of the lyrical content on charitable donations [@greitemeyer2009; @greitemeyer2009a].

<!-- Theatre: see alse Troxler et al., 2022 & Greene et al., 2018 -->

What unites previous studies on advocacy through art is that the artistic stimuli under investigation use explicit and naturalistic imagery and narration to convey their advocacy messages. However, this leaves out art that conveys social critique in an implicit, symbolic, or abstract manner.

Music beyond the song form, such as (contemporary) classical or folk music, is carried more by instruments and sounds and less by lyrics. Therefore, this kind of music has less tools for concrete narrative or imagery. Still, it is often intended to advocate for specific issues, such as TODO find more examples, maybe among Klezmer or Jazz?:

-   East-Western Divan orchestra: classical symphony orchestra to promote peace and understanding between Israel and Palestine

-   Innocents: contemporary percussion piece about wrongful incarceration

film vs. music: narrative portrayal vs. experiential immersion approach to advocate for social justice issues –\> film could increase reasoned awareness, music could increase perspective-taking/empathy

How does this kind of abstract, experiential music mobilize supportive behaviour?

music has been related to closeness

## Collective aspects

in-person event: social contagion/collective action with performers (music only) or audience members (film and music) could enhance effects

Pelowski et al., 2017 <https://doi.org/10.1037/aca0000141>

## The present studies

Hypotheses

Study 1

Study 2

# Study 1

1 introductory paragraph

## Method

### Participants

### Procedure

add webcam calibration for livestream participants, cite Shreshth

describe stimuli

describe implementation of surveys in jatos on tablets (in-person) or PCs (livestream)

### Measures

#### Interpersonal closeness

#### State empathy

#### Problem awareness

#### Supportive behaviour

#### Affect

#### Event experience

#### Person-level covariates

### Analysis

## Results

```{r}
#| label: fig-closeness-plot
#| fig-cap: "Mean and CI of closeness with Anna Vasquez across the event by time point (x-axis) and order of the media (line style), split for the in-person (left) and livestream (middle) audience of study 1, and study 2 (right). Closeness was rated on a visual analog scale ranging from 1 (0% overlap) to 7 (90% overlap). Significance levels refer to one-sided pairwise t-tests. &ast;$p < .05$, &ast;&ast;$p < .01$, &ast;&ast;&ast;$p < .001$, n.s. = not significant."
#| echo: false

closeness_lineplot <- plot_meanSE(df = combined_long, dv = "ios_anna", facet_var = "facet", ylab = "Rating", my_colours = c("#41AB5D", "#A1D99B")) +
  theme(legend.position = c(.163, .94), # move legend inside plot
        legend.direction = "horizontal") + 
  annotation_custom2(rasterGrob(icon_close, interpolate = TRUE), # add icon
                    xmin = 0.6, 1.5, 6.4, 7.2,
                    data = subset(combined_long, facet == "1:Livestream"))
  # TODO add pairwise significance tests
  # geom_signif(y_position = c(4.3, 4.3, 1.3, 1.3),
  #                     xmin = c(0.9, 1.95, 1.1, 2.15),
  #                     xmax = c(1.85, 2.9, 2.05, 3.2),
  #                     annotation = c("***", "n.s.", "*", "***"),
  #                     tip_length = 0,
  #                     # textsize = ,
  #                     # vjust = ,
  #                     color = rep(c("#41AB5D", "#41AB5D", "#A1D99B", "#A1D99B"), 3)
  #                     )

# closeness_lineplot <- combined_long %>%
#     ggplot(aes(x = timepoint,
#                y = ios_anna,
#                group = order,
#                color = order,
#                linetype = order,
#                shape = medium)) +
#     geom_line(aes(group = p_id),
#                alpha = 0.6,
#                position = position_jitter(width = 0, height = 0.2)) +
#     scale_colour_manual(values = c("darkgrey", "lightgrey"), guide = "none") +
#     new_scale_color() +
#     stat_summary(aes(color = order),
#                  fun = "mean", # connect means
#                  geom = "line",
#                  linewidth = 0.9,
#                  position = position_dodge(0.5)) +
#     stat_summary(aes(color = order),
#                  fun = "mean", # add mean
#                  geom = "point",
#                  size = 3,
#                  position = position_dodge(0.5)) +
#     stat_summary(aes(color = order),
#                  fun.data = mean_cl_boot, # add 95% bootstrapped CI with 1000 samples
#                  geom = "errorbar",
#                  width = 0.35,
#                  linewidth = 0.9,
#                  linetype = "solid",
#                  position = position_dodge(0.5),
#                  show.legend = FALSE) +
#     scale_colour_manual(values = c("#41AB5D", "#A1D99B")) +
#     guides(
#       colour = guide_legend("Order", override.aes = list(shape = NA)),
#       linetype = guide_legend("Order"),
#       shape = "none"
#     ) +
#     # coord_fixed(ratio = 0.6, ylim = c(1,7) ) +
#     # scale_x_discrete(label = sample_size[["myaxis"]]) +
#     scale_y_continuous(limits = c(1,7)) +
#     theme_bw(base_size = 11) +
#     labs(x = "Time point",
#          y = "Closeness (Anna)") +
#     theme(panel.grid.major.x = element_blank(), # remove vertical grid line
#           # legend.text=element_text(size=6),
#           legend.title=element_text(margin = margin(b = 0)),
#           legend.background = element_rect(fill = "white", color = "black"),
#           # axis.title = element_text(size=9.5),
#           axis.text.x = element_text(angle=20, hjust=0.8))
# 
# closeness_lineplot <- closeness_lineplot +
#   facet_wrap(vars(facet), scales = "free_x")
 
print(closeness_lineplot)
```

```{r}
#| label: fig-closeness-plot
#| fig-cap: "Mean and CI of empathy with Anna Vasquez across the event by time point (x-axis) and order of the media (line style), split for the in-person (left) and livestream (middle) audience of study 1, and study 2 (right). Empathy was rated on a scale ranging from 1 (not at all) to 7 (extremely). Significance levels refer to one-sided pairwise t-tests. &ast;$p < .05$, &ast;&ast;$p < .01$, &ast;&ast;&ast;$p < .001$, n.s. = not significant."
#| echo: false

empathy_lineplot <- plot_meanSE(df = combined_long, dv = "anna_empathic_concern", facet_var = "facet", ylab = "Rating", my_colours = c("#DC267F", "#D4ABB7")) +
  theme(legend.position = "top", # move legend inside plot
        legend.direction = "horizontal")

annotate_figure(empathy_lineplot, top = rasterGrob(icon_empath, x = 0.1, y = -0.5, width = 0.07, interpolate = TRUE))

```

## Discussion

2 paragraphs

# Study 2

1 introductory paragraph: explain relation to hypotheses, gap of study 1, and how study 2 fills the gap (procedure)

## Method

Study 2 manipulated one factor with two levels: Participants watched either the film or the performance. Therefore, there were only two measurement time points, before and after watching. All participants watched a stream at home, so Study 2 followed many of the same methods used for the livestream audience in Study 1. The methods for Study 2 were preregistered at OSF on June 18th, 2025 (see <https://osf.io/suyef/>), and any deviations from the preregistration are reported here. The OSF repository also contains the survey. <!-- TODO and data and analysis code? -->

### Participants

<!-- TODO after data collection: fill in final sample size. If smaller than 200, conduct sensitivity analysis? -->

<!-- TODO describe pertinent characteristics, refer to suppl for detailed tables -->

For Study 2, we recruited all participants through Prolific between June and July 2025. The study was open Tuesday through Sunday evening roughly between 5:30 and 8:30 pm Eastern Time to imitate the conditions of a livestreamed event as in Study 1. Participants had to be between 18 and 60 years old, be fluent in English, have healthy hearing, watch the event without glasses (healthy vision or correction with contact lenses), have not seen the film or the performance before, and reside in Canada. We added the last requirement to match the area of activity of our partner charity, Innocence Canada. We aimed to recruit 200 participants, 100 per condition. A simulation-based power analysis indicated that this sample size would yield a 75% power to detect the most ambiguous effect from Study 1, the interaction of medium and time on empathic concern (see preregistration for details). A total of xyz participants started the study and xyz (%) completed it, with xyz participants in the film and xyz in the performance condition. Because the film is 15 minutes longer than the performance, we set up two parallel studies on Prolific with identical descriptions, but differing duration and compensation. By signing up to the study, participants therefore blindly self-assigned to a condition (film or performance). Upon completion of the study, participants in the performance condition were compensated with 11.50 GBP, while participants in the film condition received 13 GBP (equivalent to a rate of 6 GBP per hour).

### Procedure

<!-- TODO after data collection: update how many participants -->

For Study 2, the pre-survey was administered in the same session as the event stream and the post-survey (except for one participant who filled out the pre-survey and asked to finish the remainder of the study the next day). Therefore, the procedure was similar to that used for the impromptu participants of Study 1: After giving informed consent, participants filled out a pre-survey, which assessed a baseline of the behavioural predictors interpersonal closeness, state empathy, and problem awareness. Moreover, the pre-survey included the other NAM-TPB variables and an affect measure. Participants then saw a recording of the event stream from Study 1, containing either the film (first half of the April 2nd, 2024, event) or the performance (first half of the April 4th event). After watching the stream, participants rated their event experience and the same measures already assessed at baseline, and finally the person-level covariates. At the end, we asked participants what they thought the study investigated, and we observed behaviour in support of *Innocence Canada*. Study 2 additionally included some new measures described in the next section, as well as some measures that were used to answer other research questions (see preregistration for details). The implementation of the web surveys and the integrated stream was identical to Study 1. Throughout the study, participants were instructed that they would watch a live event, even though they actually watched a recording, to create an experience comparable to the livestream in Study 1. After the study, participants were debriefed about this deception and reconsented to the use of their data. Study 2 was approved by the McMaster Research Ethics Board (#7202).

### Measures

Study 2 assessed the same measures as Study 1 (interpersonal closeness, state empathy, the variables of the NAM and TPB, supportive behaviour, affect, event experience, and person-level covariates), except for the following changes:

#### Interpersonal closeness

As in Study 1, we measured interpersonal closeness with the IOS scale [@aron1992], rated for the same target persons/groups. In addition, participants were asked to imagine an acquaintance and prompted to describe them to make sure they were visualizing a person they actually know [@cialdini1997]. Participants were then asked to imagine that this acquaintance fell victim to wrongful imprisonment (the vignette was modeled after a real case, @verschwele2020; for the full vignette see the OSF repository), and rated their closeness with the acquaintance.

#### State empathy

As in Study 1, participants read a vignette about the wrongful imprisonment of Anna Vasquez and rated their empathic concern and personal distress using the Empathic Concern Index [@batson1987]. In addition, the Empathic Concern Index was also administered after the vignette about the hypothetical wrongful imprisonment of the participant's acquaintance.

#### Problem awareness

Problem awareness and the other NAM and TPB variables were assessed using the same self-worded instrument from Study 1. The only change was in the items measuring behavioural intentions: Rather than naming *Innocence Canada,* we asked about participants' intentions to join the mailing list and donate to "an organization that fights wrongful imprisonment". Our partner organization *Innocence Canada* was only presented at the end of the study, when assessing actual behaviour, to reduce the risk of participants looking up the organization and engaging in any of the behaviours beforehand.

#### Person-level covariates

Because all participants were recruited through Prolific, rather than self-initiatively buying a ticket to the event, we did not ask participants for their motivation to attend, nor for their personal relationship with the researchers or the artists. To shorten the post-survey, we abridged the trait empathy measure, which had not shown consistent associations with supportive behaviour or its predictors in Study 1.

### Analysis

TODO

## Results

## Discussion

# General Discussion

## Citations

See [here](https://quarto.org/docs/authoring/footnotes-and-citations.html) for instructions on setting up citations and references.

A parenthetical citation requires square brackets [@CameronTrivedi2013]. This reference was in my bibliography file. An in-text citation is done like so:

@CameronTrivedi2013 make some important points ...

See [here](https://wjschne.github.io/apaquarto/writing.html#references) for explanations, examples, and citation features exclusive to apaquarto. For example, apaquarto can automatically handle possessive citations:

@schneider2012cattell ['s] position was ...

## Masking Author Identity for Peer Review

Setting `mask` to `true` will remove author names, affiliations, and correspondence from the title page. Any references listed in the `masked-citations` field will be masked as well. See [here](https://wjschne.github.io/apaquarto/writing.html#masked-citations-for-anonymous-peer-review) for more information.

## Block Quotes

Sometimes you want to give a longer quote that needs to go in its own paragraph. Block quotes are on their own line starting with the \> character. For example, @austenMansfieldPark1990 ['s] *Mansfield Park* has some memorable insights about the mind:

> If any one faculty of our nature may be called more wonderful than the rest, I do think it is memory. There seems something more speakingly incomprehensible in the powers, the failures, the inequalities of memory, than in any other of our intelligences. The memory is sometimes so retentive, so serviceable, so obedient; at others, so bewildered and so weak; and at others again, so tyrannic, so beyond control! We are, to be sure, a miracle every way; but our powers of recollecting and of forgetting do seem peculiarly past finding out. (p. 163)

## Math and Equations

Inline math uses $\LaTeX$ syntax with single dollar signs. For example, the reliability coefficient of my measure is $r_{XX}=.95$.

If you want to display and refer to a specific formula, enclose the formula in two dollar signs. After the second pair of dollar signs, place the label in curly braces. The label should have an `#eq-` prefix. To refer to the formula, use the same label but with the `@` symbol. For example, @eq-euler is Euler's Identity, which is much admired for its elegance.

$$
e^{i\pi}+1=0
$$ {#eq-euler}

A more practical example is the z-score equation seen in @eq-zscore.

$$
z=\frac{X-\mu}{\sigma}
$$ {#eq-zscore}

If no identifier label is given, a centered equation in display mode will have no identifying number:

$$
\sigma_e=\sigma_y\sqrt{1-r_{xy}^2}
$$

## Displaying Figures

Do you want the tables and figures to be at the end of the document? You can set the `floatsintext` option to false. The reference labels will work no matter where they are in the text.

A reference label for a figure must have the prefix `fig-`, and in a code chunk, the caption must be set with `fig-cap`. Captions are in [title case](https://apastyle.apa.org/style-grammar-guidelines/capitalization/title-case).

```{r}
#| label: fig-myplot
#| fig-cap: The Figure Caption
#| apa-note: This is the note below the figure.
#| fig-height: 2
#| fig-width: 3
ggplot(data.frame(x = c(0, 35)), aes(x)) +
  stat_function(fun = dchisq, 
                args = list(df = 10),
                geom = "area",
                n = 1000,
                color = NA,
                fill = "#41448780") +
  theme_void(base_size = 18)
```

To refer to any figure or table, use the `@` symbol followed by the reference label (e.g., @fig-myplot).

## Displaying Tables

We can make a table the same way as a figure. Generating a table that conforms to APA format in all document formats can be tricky. When the table is simple, the `kable` function from knitr works well. Feel free to experiment with different methods, but I have found that David Gohel's [flextable](https://davidgohel.github.io/flextable/) to be the best option when I need something more complex.

```{r}
#| label: tbl-mytable
#| tbl-cap: The Table Caption. 
#| apa-note: The note below the table.
tibble(Numbers = seq(1,4), Letters = LETTERS[seq(Numbers)]) %>%
  knitr::kable()

```

To refer to this table in text, use the `@` symbol followed by the reference label like so: As seen in @tbl-mytable, the first few numbers and letters of the alphabet are displayed.

## Footnotes

A footnote is usually displayed at the bottom of the page on which the footnote occurs. A short note can be specified with the `^[My note here]` syntax.[^1] A longer note can be specified with the `[^id]` syntax with the text specified on a separate line like so `[^id]: Text here`.[^2]

[^1]: Here is my short footnote!

[^2]: This is a longer footnote. If it has multiple paragraphs, subsequent paragraphs need to be indented with two tabs.

    This paragraph is still part of the footnote because it is indented with two tabs.

A regular paragraph without any indentation is not part of the footnote and will be part of the main body of the document.

## Hypotheses, Aims, and Objectives

The last paragraph of the introduction usually states the specific hypotheses of the study, often in a way that links them to the research design.

# Method

General remarks on method. This paragraph is optional.

Not all papers require each of these sections. Edit them as needed. Consult the [Journal Article Reporting Standards](https://apastyle.apa.org/jars) for what is needed for your type of article.

## Participants

Who are they? How were they recruited? Report criteria for participant inclusion and exclusion. Perhaps some basic demographic stats are in order. A table is a great way to avoid repetition in statistical reporting.

## Measures

This section can also be titled **Materials** or **Apparatus**. Whatever tools, equipment, or measurement devices used in the study should be described.

### Measure A

Describe Measure A.

### Measure B

Describe Measure B.

#### Subscale B1

A paragraph after a 4th-level header will appear on the same line as the header.

#### Subscale B2

A paragraph after a 4th-level header will appear on the same line as the header.

##### Subscale B2a

A paragraph after a 5th-level header will appear on the same line as the header.

##### Subscale B2b

A paragraph after a 5th-level header will appear on the same line as the header.

## Procedure

What did participants do? How are the data going to be analyzed?

# Results

## Descriptive Statistics

Describe the basic characteristics of the primary variables. My ideal is to describe the variables well enough that someone conducting a meta-analysis can include the study without needing to ask for additional information.

<!-- Add Additional Sections as Needed -->

@tbl-mymarkdowntable2 is an example of a plain markdown table. Note the that the caption begins with a colon.

| Letters | Numbers |
|:-------:|:-------:|
|    A    |    1    |
|    B    |    2    |
|    C    |    3    |

: My Caption. {#tbl-mymarkdowntable2 apa-note="My note"}

# Discussion

Describe results in non-statistical terms. <!-- Add sections as needed. -->

## Limitations and Future Directions

Every study has limitations. Based on this study, some additional steps might include...

## Conclusion

Describe the main point of the paper.

# References

<!-- References will auto-populate in the refs div below -->

::: {#refs}
:::

# My Appendix Title {#apx-a}

Appendices are created as level 1 headings with an identifier with an `#apx-` prefix. Appendix titles should be in title case and should describe the content of the appendix.

If there is only one appendix, the label automatically inserted above the the appendix title will be **Appendix**. If there are multiple appendices, the labels **Appendix A**, **Appendix B**, **Appendix C** and so forth will be inserted above the titles.

To cite an appendix as a whole, reference it with the `@apx-` prefix. For example, see @apx-a and @apx-b.

This is an appendix with a table using markdown (see @tbl-letters).

| Col 1 | Col 2 | Col 3 |
|-------|-------|-------|
| A     | B     | C     |
| E     | F     | G     |
| A     | G     | G     |

: My Caption {#tbl-letters apa-note="These are letters."}

# Another Appendix {#apx-b}

See @fig-appendfig, an example of an imported graphic using markdown syntax.

![Appendix Figure](sampleimage.png){#fig-appendfig apa-note="A *note* below the figure"}
